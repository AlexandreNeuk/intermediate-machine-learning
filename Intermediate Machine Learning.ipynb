{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work with data from the [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course) to predict home prices in Iowa using 79 explanatory variables describing (almost) every aspect of the homes.  \n",
    "\n",
    "![Ames Housing dataset image](https://i.imgur.com/lTJVG4e.png)\n",
    "\n",
    "Run the next code cell without changes to load the training and validation features in `X_train` and `X_valid`, along with the prediction targets in `y_train` and `y_valid`.  The test features are loaded in `X_test`.  (_If you need to review **features** and **prediction targets**, please check out [this short tutorial](https://www.kaggle.com/dansbecker/your-first-machine-learning-model).  To read about model **validation**, look [here](https://www.kaggle.com/dansbecker/model-validation).  Alternatively, if you'd prefer to look through a full course to review all of these topics, start [here](https://www.kaggle.com/learn/machine-learning).)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('data/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('data/test.csv', index_col='Id')\n",
    "\n",
    "# Obtain target and predictors\n",
    "y = X_full.SalePrice\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = X_full[features].copy()\n",
    "X_test = X_test_full[features].copy()\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>11694</td>\n",
       "      <td>2007</td>\n",
       "      <td>1828</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>6600</td>\n",
       "      <td>1962</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>13360</td>\n",
       "      <td>1921</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>13265</td>\n",
       "      <td>2002</td>\n",
       "      <td>1689</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>13704</td>\n",
       "      <td>2001</td>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
       "Id                                                                    \n",
       "619    11694       2007      1828         0         2             3   \n",
       "871     6600       1962       894         0         1             2   \n",
       "93     13360       1921       964         0         1             2   \n",
       "818    13265       2002      1689         0         2             3   \n",
       "303    13704       2001      1541         0         2             3   \n",
       "\n",
       "     TotRmsAbvGrd  \n",
       "Id                 \n",
       "619             9  \n",
       "871             5  \n",
       "93              5  \n",
       "818             7  \n",
       "303             6  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell defines five different random forest models.  Run this code cell without changes.  (_To review **random forests**, look [here](https://www.kaggle.com/dansbecker/random-forests)._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the models\n",
    "model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\n",
    "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
    "model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the best model out of the five, we define a function score_model() below. This function returns the mean absolute error (MAE) from the validation set. Recall that the best model will obtain the lowest MAE. (To review mean absolute error, look here.)\n",
    "\n",
    "Run the code cell without changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 MAE: 24015\n",
      "Model 2 MAE: 23740\n",
      "Model 3 MAE: 23528\n",
      "Model 4 MAE: 23996\n",
      "Model 5 MAE: 23706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different models\n",
    "def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n",
    "    model.fit(X_t, y_t)\n",
    "    preds = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, preds)\n",
    "\n",
    "for i in range(0, len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    print(\"Model %d MAE: %d\" % (i+1, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above results to fill in the line below.  Which model is the best model?  Your answer should be one of `model_1`, `model_2`, `model_3`, `model_4`, or `model_5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. You know how to evaluate what makes an accurate model. Now it's time to go through the modeling process and make predictions. In the line below, create a Random Forest model with the variable name my_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = RandomForestRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell without changes. The code fits the model to the training and validation data, and then generates test predictions that are saved to a CSV file. These test predictions can be submitted directly to the competition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "my_model.fit(X, y)\n",
    "\n",
    "# Generate test predictions\n",
    "preds_test = my_model.predict(X_test)\n",
    "\n",
    "# Save predictions in format used for competition scoring\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('data/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('data/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "X_test = X_test_full.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next code cell to print the first five rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>90.0</td>\n",
       "      <td>11694</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>452.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6600</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13360</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1921</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13265</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>857</td>\n",
       "      <td>150</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13704</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>843</td>\n",
       "      <td>468</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                           \n",
       "619          20         90.0    11694            9            5       2007   \n",
       "871          20         60.0     6600            5            5       1962   \n",
       "93           30         80.0    13360            5            7       1921   \n",
       "818          20          NaN    13265            8            5       2002   \n",
       "303          20        118.0    13704            7            5       2001   \n",
       "\n",
       "     YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n",
       "Id                                                     ...               \n",
       "619          2007       452.0          48           0  ...         774   \n",
       "871          1962         0.0           0           0  ...         308   \n",
       "93           2006         0.0         713           0  ...         432   \n",
       "818          2002       148.0        1218           0  ...         857   \n",
       "303          2002       150.0           0           0  ...         843   \n",
       "\n",
       "     WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
       "Id                                                                              \n",
       "619           0          108              0          0          260         0   \n",
       "871           0            0              0          0            0         0   \n",
       "93            0            0             44          0            0         0   \n",
       "818         150           59              0          0            0         0   \n",
       "303         468           81              0          0            0         0   \n",
       "\n",
       "     MiscVal  MoSold  YrSold  \n",
       "Id                            \n",
       "619        0       7    2007  \n",
       "871        0       8    2009  \n",
       "93         0       8    2009  \n",
       "818        0       7    2008  \n",
       "303        0       1    2006  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can already see a few missing values in the first several rows. In the next step, you'll obtain a more comprehensive understanding of the missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 36)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage    212\n",
      "MasVnrArea       6\n",
      "GarageYrBlt     58\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above output to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: How many rows are in the training data?\n",
    "num_rows = 1168\n",
    "\n",
    "# Fill in the line below: How many columns in the training data\n",
    "# have missing values?\n",
    "num_cols_with_missing = 3\n",
    "\n",
    "# Fill in the line below: How many missing entries are contained in \n",
    "# all of the training data?\n",
    "tot_missing = 276"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare different approaches to dealing with missing values, you'll use the same `score_dataset()` function from the tutorial.  This function reports the [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) from a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you'll preprocess the data in `X_train` and `X_valid` to remove columns with missing values.  Set the preprocessed DataFrames to `reduced_X_train` and `reduced_X_valid`, respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Drop columns with missing values):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next code cell to impute missing values with the mean value along each column. Set the preprocessed DataFrames to imputed_X_train and imputed_X_valid. Make sure that the column names match those in X_train and X_valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fill in the lines below: imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Imputation):\n",
      "18062.894611872147\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final step, you'll use any approach of your choosing to deal with missing values.  Once you've preprocessed the training and validation features, you'll train and evaluate a random forest model.  Then, you'll preprocess the test data before generating predictions that can be submitted to the competition!\n",
    "\n",
    "Use the next code cell to preprocess the training and validation data.  Set the preprocessed DataFrames to `final_X_train` and `final_X_valid`.  **You can use any approach of your choosing here!**  in order for this step to be marked as correct, you need only ensure:\n",
    "- the preprocessed DataFrames have the same number of columns,\n",
    "- the preprocessed DataFrames have no missing values, \n",
    "- `final_X_train` and `y_train` have the same number of rows, and\n",
    "- `final_X_valid` and `y_valid` have the same number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "final_imputer = SimpleImputer(strategy='median')\n",
    "final_X_train = pd.DataFrame(final_imputer.fit_transform(X_train))\n",
    "final_X_valid = pd.DataFrame(final_imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "final_X_train.columns = X_train.columns\n",
    "final_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell to train and evaluate a random forest model.  (*Note that we don't use the `score_dataset()` function above, because we will soon use the trained model to generate test predictions!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Your approach):\n",
      "17791.59899543379\n"
     ]
    }
   ],
   "source": [
    "# Define and fit model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(final_X_train, y_train)\n",
    "\n",
    "# Get validation predictions and MAE\n",
    "preds_valid = model.predict(final_X_valid)\n",
    "print(\"MAE (Your approach):\")\n",
    "print(mean_absolute_error(y_valid, preds_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next code cell to preprocess your test data. Make sure that you use a method that agrees with how you preprocessed the training and validation data, and set the preprocessed test features to final_X_test.\n",
    "\n",
    "Then, use the preprocessed test features and the trained model to generate test predictions in preds_test.\n",
    "\n",
    "In order for this step to be marked correct, you need only ensure:\n",
    "\n",
    "the preprocessed test DataFrame has no missing values, and\n",
    "final_X_test has the same number of rows as X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: preprocess test data\n",
    "final_X_test = pd.DataFrame(final_imputer.transform(X_test))\n",
    "\n",
    "# Fill in the line below: get test predictions\n",
    "preds_test = model.predict(final_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission_missing_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare different models, you'll use the same score_dataset() function from the tutorial. This function reports the mean absolute error (MAE) from a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('data/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('data/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll drop columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns with categorical data\n",
    "\n",
    "You'll get started with the most straightforward approach. Use the code cell below to preprocess the data in X_train and X_valid to remove columns with categorical data. Set the preprocessed DataFrames to drop_X_train and drop_X_valid, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the lines below: drop columns in training and validation data\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell to get the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding\n",
    "\n",
    "Before jumping into label encoding, we'll investigate the dataset. Specifically, we'll look at the 'Condition2' column. The code cell below prints the unique entries in both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now write code to:\n",
    "\n",
    "fit a label encoder to the training data, and then\n",
    "use it to transform both the training and validation data,\n",
    "you'll get an error. Can you see why this is the case? (You'll need to use the above output to answer this question.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: Fitting a label encoder to a column in the training data creates a corresponding integer-valued label for each unique value that appears in the training data. In the case that the validation data contains values that don't also appear in the training data, the encoder will throw an error, because these values won't have an integer assigned to them. Notice that the 'Condition2' column in the validation data contains the values 'RRAn' and 'RRNn', but these don't appear in the training data -- thus, if we try to use a label encoder with scikit-learn, the code will throw an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue.  For instance, you can write a custom label encoder to deal with new categories.  The simplest approach, however, is to drop the problematic categorical columns.  \n",
    "\n",
    "Run the code cell below to save the problematic columns to a Python list `bad_label_cols`.  Likewise, columns that can be safely label encoded are stored in `good_label_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be label encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'BldgType', 'HouseStyle', 'ExterQual', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Condition1', 'Exterior2nd', 'Neighborhood', 'HeatingQC', 'Foundation', 'ExterCond', 'RoofMatl', 'Heating', 'SaleType', 'RoofStyle', 'LandSlope', 'Utilities', 'Exterior1st', 'Condition2', 'Functional']\n"
     ]
    }
   ],
   "source": [
    "# All categorical columns\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely label encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_train[col]) == set(X_valid[col])]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next code cell to label encode the data in X_train and X_valid. Set the preprocessed DataFrames to label_X_train and label_X_valid, respectively.\n",
    "\n",
    "We have provided code below to drop the categorical columns in bad_label_cols from the dataset.\n",
    "You should label encode the categorical columns in good_label_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Apply label encoder to each column with categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "for col in good_label_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell to get the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Label Encoding):\n",
      "17575.291883561644\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating cardinality\n",
    "\n",
    "So far, you've tried two different approaches to dealing with categorical variables.  And, you've seen that encoding categorical data yields better results than removing columns from the dataset.\n",
    "\n",
    "Soon, you'll try one-hot encoding.  Before then, there's one additional topic we need to cover.  Begin by running the next code cell without changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows, for each column with categorical data, the number of unique values in the column.  For instance, the `'Street'` column in the training data has two unique values: `'Grvl'` and `'Pave'`, corresponding to a gravel road and a paved road, respectively.\n",
    "\n",
    "We refer to the number of unique entries of a categorical variable as the **cardinality** of that categorical variable.  For instance, the `'Street'` variable has cardinality 2.\n",
    "\n",
    "Use the output above to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: How many categorical variables in the training data\n",
    "# have cardinality greater than 10?\n",
    "high_cardinality_numcols = 3\n",
    "\n",
    "# Fill in the line below: How many columns are needed to one-hot encode the \n",
    "# 'Neighborhood' variable in the training data?\n",
    "num_cols_neighborhood = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset.  For this reason, we typically will only one-hot encode columns with relatively low cardinality.  Then, high cardinality columns can either be dropped from the dataset, or we can use label encoding.\n",
    "\n",
    "As an example, consider a dataset with 10,000 rows, and containing one categorical column with 100 unique entries.  \n",
    "- If this column is replaced with the corresponding one-hot encoding, how many entries are added to the dataset?  \n",
    "- If we instead replace the column with the label encoding, how many entries are added?  \n",
    "\n",
    "Use your answers to fill in the lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: How many entries are added to the dataset by \n",
    "# replacing the column with a one-hot encoding?\n",
    "OH_entries_added = 1e4*100 - 1e4\n",
    "\n",
    "# Fill in the line below: How many entries are added to the dataset by\n",
    "# replacing the column with a label encoding?\n",
    "label_entries_added = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "In this step, you'll experiment with one-hot encoding. But, instead of encoding all of the categorical variables in the dataset, you'll only create a one-hot encoding for columns with cardinality less than 10.\n",
    "\n",
    "Run the code cell below without changes to set low_cardinality_cols to a Python list containing the columns that will be one-hot encoded. Likewise, high_cardinality_cols contains a list of categorical columns that will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Neighborhood', 'Exterior1st', 'Exterior2nd']\n"
     ]
    }
   ],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next code cell to one-hot encode the data in `X_train` and `X_valid`.  Set the preprocessed DataFrames to `OH_X_train` and `OH_X_valid`, respectively.  \n",
    "- The full list of categorical columns in the dataset can be found in the Python list `object_cols`.\n",
    "- You should only one-hot encode the categorical columns in `low_cardinality_cols`.  All other categorical columns should be dropped from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Use as many lines of code as you need!\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "17525.345719178084\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines are a simple way to keep your data preprocessing and modeling code organized. Specifically, a pipeline bundles preprocessing and modeling steps so you can use the whole bundle as if it were a single step.\n",
    "\n",
    "Many data scientists hack together models without pipelines, but pipelines have some important benefits. Those include:\n",
    "\n",
    "1) Cleaner Code: Accounting for data at each step of preprocessing can get messy. With a pipeline, you won't need to manually keep track of your training and validation data at each step.\n",
    "\n",
    "2) Fewer Bugs: There are fewer opportunities to misapply a step or forget a preprocessing step.\n",
    "\n",
    "3) Easier to Productionize: It can be surprisingly hard to transition a model from a prototype to something deployable at scale. We won't go into the many related concerns here, but pipelines can help.\n",
    "\n",
    "4) More Options for Model Validation: You will see an example in the next tutorial, which covers cross-validation.\n",
    "\n",
    "Run the next code cell without changes to load the training and validation sets in X_train, X_valid, y_train, and y_valid. The test set is loaded in X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('data/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('data/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>857</td>\n",
       "      <td>150</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>843</td>\n",
       "      <td>468</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSZoning Street Alley LotShape LandContour Utilities LotConfig LandSlope  \\\n",
       "Id                                                                             \n",
       "619       RL   Pave   NaN      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "871       RL   Pave   NaN      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "93        RL   Pave  Grvl      IR1         HLS    AllPub    Inside       Gtl   \n",
       "818       RL   Pave   NaN      IR1         Lvl    AllPub   CulDSac       Gtl   \n",
       "303       RL   Pave   NaN      IR1         Lvl    AllPub    Corner       Gtl   \n",
       "\n",
       "    Condition1 Condition2  ... GarageArea WoodDeckSF OpenPorchSF  \\\n",
       "Id                         ...                                     \n",
       "619       Norm       Norm  ...        774          0         108   \n",
       "871       PosN       Norm  ...        308          0           0   \n",
       "93        Norm       Norm  ...        432          0           0   \n",
       "818       Norm       Norm  ...        857        150          59   \n",
       "303       Norm       Norm  ...        843        468          81   \n",
       "\n",
       "    EnclosedPorch 3SsnPorch ScreenPorch PoolArea MiscVal MoSold YrSold  \n",
       "Id                                                                      \n",
       "619             0         0         260        0       0      7   2007  \n",
       "871             0         0           0        0       0      8   2009  \n",
       "93             44         0           0        0       0      8   2009  \n",
       "818             0         0           0        0       0      7   2008  \n",
       "303             0         0           0        0       0      1   2006  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell uses code from the tutorial to preprocess the data and train a model.  Run this code without changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 17861.780102739725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = clf.predict(X_valid)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve the performance\n",
    "\n",
    "\n",
    "Now, it's your turn! In the code cell below, define your own preprocessing steps and random forest model. Fill in values for the following variables:\n",
    "\n",
    "numerical_transformer\n",
    "categorical_transformer\n",
    "model\n",
    "To pass this part of the exercise, you need only define valid preprocessing steps and a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass this step, you need to have defined a pipeline in Part A that achieves lower MAE than the code above. You're encouraged to take your time here and try out many different approaches, to see how low you can get the MAE! (If your code does not pass, please amend the preprocessing steps and model in Part A.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 17385.53157534247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = my_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission_pipeline2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is cross-validation?\n",
    "In cross-validation, we run our modeling process on different subsets of the data to get multiple measures of model quality.\n",
    "\n",
    "For example, we could begin by dividing the data into 5 pieces, each 20% of the full dataset. In this case, we say that we have broken the data into 5 \"folds\".\n",
    "\n",
    "You will work with the [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course) from the previous exercise. \n",
    "\n",
    "Run the next code cell without changes to load the training and validation sets in `X_train`, `X_valid`, `y_train`, and `y_valid`.  The test set is loaded in `X_test`.\n",
    "\n",
    "For simplicity, we drop categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "train_data = pd.read_csv('data/train.csv', index_col='Id')\n",
    "test_data = pd.read_csv('data/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = train_data.SalePrice              \n",
    "train_data.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>836</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                          \n",
       "1           60         65.0     8450            7            5       2003   \n",
       "2           20         80.0     9600            6            8       1976   \n",
       "3           60         68.0    11250            7            5       2001   \n",
       "4           70         60.0     9550            7            5       1915   \n",
       "5           60         84.0    14260            8            5       2000   \n",
       "\n",
       "    YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n",
       "Id                                                    ...               \n",
       "1           2003       196.0         706           0  ...         548   \n",
       "2           1976         0.0         978           0  ...         460   \n",
       "3           2002       162.0         486           0  ...         608   \n",
       "4           1970         0.0         216           0  ...         642   \n",
       "5           2000       350.0         655           0  ...         836   \n",
       "\n",
       "    WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
       "Id                                                                             \n",
       "1            0           61              0          0            0         0   \n",
       "2          298            0              0          0            0         0   \n",
       "3            0           42              0          0            0         0   \n",
       "4            0           35            272          0            0         0   \n",
       "5          192           84              0          0            0         0   \n",
       "\n",
       "    MiscVal  MoSold  YrSold  \n",
       "Id                           \n",
       "1         0       2    2008  \n",
       "2         0       5    2007  \n",
       "3         0       9    2008  \n",
       "4         0       2    2006  \n",
       "5         0      12    2008  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns only\n",
    "numeric_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float64']]\n",
    "X = train_data[numeric_cols].copy()\n",
    "X_test = test_data[numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you've learned how to build pipelines with scikit-learn.  For instance, the pipeline below will use [`SimpleImputer()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) to replace missing values in the data, before using [`RandomForestRegressor()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) to train a random forest model to make predictions.  We set the number of trees in the random forest model with the `n_estimators` parameter, and setting `random_state` ensures reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have also learned how to use pipelines in cross-validation.  The code below uses the [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function to obtain the mean absolute error (MAE), averaged across five different folds.  Recall we set the number of folds with the `cv` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE score: 18276.410356164386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a useful function\n",
    "\n",
    "In this exercise, you'll use cross-validation to select parameters for a machine learning model.\n",
    "\n",
    "Begin by writing a function `get_score()` that reports the average (over three cross-validation folds) MAE of a machine learning pipeline that uses:\n",
    "- the data in `X` and `y` to create folds,\n",
    "- `SimpleImputer()` (with all parameters left as default) to replace missing values, and\n",
    "- `RandomForestRegressor()` (with `random_state=0`) to fit a random forest model.\n",
    "\n",
    "The `n_estimators` parameter supplied to `get_score()` is used when setting the number of trees in the random forest model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_estimators):\n",
    "    \"\"\"Return the average MAE over 3 CV folds of random forest model.\n",
    "    \n",
    "    Keyword argument:\n",
    "    n_estimators -- the number of trees in the forest\n",
    "    \"\"\"\n",
    "    my_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', SimpleImputer()),\n",
    "        ('model', RandomForestRegressor(n_estimators, random_state=0))\n",
    "    ])\n",
    "    scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                                  cv=3,\n",
    "                                  scoring='neg_mean_absolute_error')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test different parameter values\n",
    "Now, you will use the function that you defined in Step 1 to evaluate the model performance corresponding to eight different values for the number of trees in the random forest: 50, 100, 150, ..., 300, 350, 400.\n",
    "\n",
    "Store your results in a Python dictionary results, where results[i] is the average MAE returned by get_scores(i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i in range(1,9):\n",
    "    results[50*i] = get_score(50*i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best parameter value\n",
    "Use the next cell to visualize your results from Step 2. Run the code without changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results.keys(), results.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the results, which value for n_estimators seems best for the random forest model? Use your answer to set the value of n_estimators_best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_best = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
